# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WgplMTIy_iXbyd_5ghLYaBvjATZhvlIl
"""

import zipfile

zip_path = "/content/archive.zip"  # Path to your ZIP file
extract_path = "/content/Rice_Image_Dataset"  # Path where files will be extracted

try:
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("Dataset successfully extracted to:", extract_path)
except Exception as e:
    print("An error occurred during extraction:", e)

import cv2
import numpy as np
from matplotlib import pyplot as plt
import os
import random

def classifyAspectRatio(aspectRatio):
    """
    This is Categorizes rice grains into different types (Slender, Medium, Bold, Round)
    by evaluating the width-to-height ratio (aspect ratio). The ratio is rounded
    to make the classification more consistent.
    """
    aspectRatio = round(aspectRatio, 1)  # Simplifying the ratio for classification of the grain
    if aspectRatio >= 3:
        return "Slender"  # Grain is long and thin
    elif 2.1 <= aspectRatio < 3:
        return "Medium"  # Grain has a moderate shape
    elif 1.1 <= aspectRatio < 2.1:
        return "Bold"  # Grain is shorter and wider
    else:
        return "Round"  # Grain is almost circular

def analyzeImage(image_path):
    """
    Processes an image to analyze rice grains:
    - Detects shapes using contours
    - Classifies each grain based on aspect ratio
    - Computes statistics (total grains, average shape ratio)
    - Displays intermediate steps (e.g., thresholding, filtering)

    Args:
        image_path (str): Path to the input image.

    Returns:
        tuple: Total grains detected, average aspect ratio, and grain type counts.
    """
    print("Processing:", image_path)  # Display the image being worked on

    # Load the image in grayscale (black-and-white format)
    img = cv2.imread(image_path, 0)

    # Convert grayscale image into a binary image (black-and-white regions)
    _, binary = cv2.threshold(img, 160, 255, cv2.THRESH_BINARY)

    # Reduce image noise by smoothing with an average filter
    kernel = np.ones((5, 5), np.float32) / 9  # Small 5x5 square filter
    filtered = cv2.filter2D(binary, -1, kernel)

    # Prepare for morphological operations (erosion and dilation)
    morphkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))

    # Shrink smaller areas (noise) using erosion
    eroded = cv2.erode(filtered, morphkernel, iterations=1)

    # Expand the remaining shapes for better detection using dilation
    dilated = cv2.dilate(eroded, morphkernel, iterations=1)

    # Detect edges in the cleaned-up image
    edges = cv2.Canny(dilated, 100, 200)

    # Identify individual grains using contours (outlines of shapes)
    contours, _ = cv2.findContours(eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    print("Number of grains detected =", len(contours))

    # Classify each grain and compute aspect ratio statistics
    total_aspect_ratio = 0
    classifications = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)  # Get a rectangle around each grain
        aspect_ratio = float(w) / h if w >= h else float(h) / w  # Ensure ratio >= 1
        classifications.append(classifyAspectRatio(aspect_ratio))  # Classify the grain
        total_aspect_ratio += aspect_ratio

    # Compute average aspect ratio
    avg_aspect_ratio = total_aspect_ratio / len(contours) if contours else 0

    # Summarize the types of grains detected
    class_counts = {cls: classifications.count(cls) for cls in set(classifications)}
    print("Class Counts:", class_counts)

    # Visualize each processing step and the final edge detection
    plottingImages([img, binary, filtered, eroded, dilated, edges],
                ["Original", "Binary", "Filtered", "Eroded", "Dilated", "Edges"])

    # Return key metrics for this image
    return len(contours), avg_aspect_ratio, class_counts

def selectRandomImage(dataset_folder):
    """
    Finds a random image from the dataset folder by searching subdirectories
    for supported image file types (.png, .jpg, .jpeg). If no images are found,
    it notifies the user.

    Args:
        dataset_folder (str): Path to the root folder containing images.

    Returns:
        str: File path of the randomly chosen image or None if no image exists.
    """
    image_files = []  # Collect all valid image file paths
    for category in os.listdir(dataset_folder):  # Check subdirectories
        category_path = os.path.join(dataset_folder, category)
        if os.path.isdir(category_path):  # Skip if not a directory
            for file_name in os.listdir(category_path):  # Look inside this subfolder
                if file_name.endswith(('.png', '.jpg', '.jpeg')):  # Only keep image files
                    image_files.append(os.path.join(category_path, file_name))

    if not image_files:  # If no images found in any subfolder
        print("No images found in the dataset.")
        return None

    return random.choice(image_files)  # Pick one image randomly


def plottingImages(images, titles):
    """
    Displays a series of images in a grid layout for comparison.

    Args:
        images (list): List of images to display.
        titles (list): Corresponding titles for the images.
    """
    rows, cols = 2, 3  # Define the grid layout (2 rows x 3 columns)
    for idx, (img, title) in enumerate(zip(images, titles)):
        plt.subplot(rows, cols, idx + 1)  # Position the current image
        plt.imshow(img, 'gray')  # Show in grayscale
        plt.title(title)  # Add the title
    plt.show()  # Render all images


# Main script to execute the rice grain analysis
dataset_folder = "/content/Rice_Image_Dataset/Rice_Image_Dataset"  # setting path to dataset

# Pick a random image for analysis
random_image_path = selectRandomImage(dataset_folder)

if random_image_path:  # Proceed if an image was successfully picked
    total_grains, avg_aspect_ratio, class_counts = analyzeImage(random_image_path)
    print("Results:", total_grains, avg_aspect_ratio, class_counts)
else:
    print("Dataset is empty or not properly structured.")

